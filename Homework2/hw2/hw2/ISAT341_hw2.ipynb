{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Two - Classification\n",
    "## Objective\n",
    "\n",
    "As a result of completing this exercise you should be able to:\n",
    "\n",
    "- Understand the concept of Classification (binary and multi-class classifier)\n",
    "- Understand the concept of K Nearest Neighbors (KNN)\n",
    "- Understand the concept of Decision Tree\n",
    "- Understand the concept of Support Vector Machine (SVM)\n",
    "- Process external and real-world data properly\n",
    "- Build the classification models using above learning algorithms using `scikit-learn`\n",
    "- Do model evaluation using classification reports using `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Section\n",
    "This homework includes three coding sections (one section for one learning algorithm) and one disucssion sectioni. You will build classification models using different approaches (i.e., KNN, decision tree, and SVM) with sickit-learn module in Python . \n",
    "\n",
    "### Submission\n",
    "The assignment should be submitted on Canvas. You will submit a zip file containing a single Jupyter Notebook(ipynb file) and two subfolders (\"images\" and \"datasets\"). In the \"datasets\" folder, please include the data set used for this assignment. In the \"images\" folder, please include any images used or created for this assignment.  \n",
    "\n",
    "- Name you zip file as hw2_$\\lt$your JMU eid$\\gt$.zip. For example, Dr. Yang's eid is yang4cx, then the submission would be hw2_yang4cx.zip\n",
    "- Please make sure your zip file is in a valid format and can be unzip before your sumbit it\n",
    "\n",
    "### Some useful webpage from Scikit-Learn library\n",
    "- https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "- https://scikit-learn.org/stable/tutorial/statistical_inference/settings.html\n",
    "- https://scikit-learn.org/stable/modules/neighbors.html\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "- https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this assignment, we will apply diverse classficiation models to an external dataset to classify glass. Imagine that you are working for CSI. Your colleagues hand you some samples of glass from some crime scene and you are asked to figure out what type of glass are they.\n",
    "\n",
    "Please build predictive models that answers the question: \"Which type of glass does a sample belong to\" using the glass data (i.e., refractive index, sodium, ..., and iron) and the machine learning algorithms we have learned.\n",
    "\n",
    "<a id=\"datasource\"></a>\n",
    "\n",
    "### Data source:\n",
    "The data are from Kaggle and more details as well as data description can be found at https://www.kaggle.com/uciml/glass. (The dataset is the \"glass.csv\" on the website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass = pd.read_csv(\"./glass.csv\")\n",
    "print(glass.shape)\n",
    "\n",
    "# provide information on first five samples\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the keys in builit-in data\n",
    "list(glass.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "# information on data features\n",
    "glass.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: (214, 9)\n",
      "Class labels: [1 2 3 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# assign features and targets to variables\n",
    "X = pd.DataFrame(glass.drop([\"Type\"], axis = 1),\n",
    "            columns=['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe'])\n",
    "y = glass.Type\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 40, stratify = y)\n",
    "\n",
    "\n",
    "#checking data set\n",
    "print('Feature dimension:', X.shape)\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9)\n"
     ]
    }
   ],
   "source": [
    "# how many samples in training data\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 9)\n"
     ]
    }
   ],
   "source": [
    "# how many samples in test data\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe\n",
      "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
      "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
      "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
      "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
      "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
      "..       ...    ...   ...   ...    ...   ...   ...   ...  ...\n",
      "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
      "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
      "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
      "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
      "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
      "\n",
      "[214 rows x 9 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "209    7\n",
      "210    7\n",
      "211    7\n",
      "212    7\n",
      "213    7\n",
      "Name: Type, Length: 214, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# double check values in the variables\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RI     Na    Mg    Al     Si     K     Ca    Ba    Fe\n",
      "203  1.51658  14.80  0.00  1.99  73.11  0.00   8.28  1.71  0.00\n",
      "47   1.52667  13.99  3.70  0.71  71.57  0.02   9.82  0.00  0.10\n",
      "115  1.51846  13.41  3.89  1.33  72.38  0.51   8.28  0.00  0.00\n",
      "151  1.52127  14.32  3.90  0.83  71.50  0.00   9.49  0.00  0.00\n",
      "192  1.51623  14.20  0.00  2.79  73.46  0.04   9.04  0.40  0.09\n",
      "..       ...    ...   ...   ...    ...   ...    ...   ...   ...\n",
      "161  1.51934  13.64  3.54  0.75  72.65  0.16   8.89  0.15  0.24\n",
      "62   1.52172  13.51  3.86  0.88  71.79  0.23   9.54  0.00  0.11\n",
      "30   1.51768  12.65  3.56  1.30  73.08  0.61   8.69  0.00  0.14\n",
      "53   1.51837  13.14  2.84  1.28  72.85  0.55   9.07  0.00  0.00\n",
      "166  1.52151  11.03  1.71  1.56  73.44  0.58  11.62  0.00  0.00\n",
      "\n",
      "[171 rows x 9 columns]\n",
      "203    7\n",
      "47     1\n",
      "115    2\n",
      "151    3\n",
      "192    7\n",
      "      ..\n",
      "161    3\n",
      "62     1\n",
      "30     1\n",
      "53     1\n",
      "166    5\n",
      "Name: Type, Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load necessary package and methods\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardized the features in both the training and test set \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning - Training a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build your KNN model\n",
    "# load necessary package and methods\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# set the classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           metric='minkowski')\n",
    "\n",
    "# fit the classifier from training set\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for a new sample with features as\n",
    "\n",
    "RI | Na | Mg | Al | Si | K | Ca | Ba | Fe\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- \n",
    "1.6010| 12.51 | 1.67 | 2.15 | 72.19 | 0.79 | 9.3 | 0.28 | 0.54 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize the features\n",
    "test_wstd = sc.transform([[1.6010, 12.51, 1.67, 2.15, 72.19, 0.79, 9.3, 0.28, 0.54]])\n",
    "\n",
    "# prediction\n",
    "knn.predict(test_wstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for all the samples in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 6, 2, 1, 1,\n",
       "       2, 7, 1, 1, 7, 2, 1, 2, 1, 2, 1, 7, 1, 7, 2, 7, 7, 1, 1, 2, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the label for all samples in test set\n",
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.79      0.59        14\n",
      "           2       0.62      0.53      0.57        15\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.58        43\n",
      "   macro avg       0.49      0.44      0.44        43\n",
      "weighted avg       0.53      0.58      0.54        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for KNN\n",
    "# define y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# print\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: (214, 10)\n",
      "Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n",
      "None\n",
      "Summary:\n",
      "                RI          Na          Mg          Al          Si           K  \\\n",
      "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
      "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
      "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
      "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
      "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
      "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
      "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
      "\n",
      "               Ca          Ba          Fe        Type  \n",
      "count  214.000000  214.000000  214.000000  214.000000  \n",
      "mean     8.956963    0.175047    0.057009    2.780374  \n",
      "std      1.423153    0.497219    0.097439    2.103739  \n",
      "min      5.430000    0.000000    0.000000    1.000000  \n",
      "25%      8.240000    0.000000    0.000000    1.000000  \n",
      "50%      8.600000    0.000000    0.000000    2.000000  \n",
      "75%      9.172500    0.000000    0.100000    3.000000  \n",
      "max     16.190000    3.150000    0.510000    7.000000  \n"
     ]
    }
   ],
   "source": [
    "# double check the loaded data\n",
    "# dimensions\n",
    "print(\"Dimension:\", glass.shape)\n",
    "\n",
    "# data information\n",
    "print(\"Information:\")\n",
    "print(glass.info())\n",
    "\n",
    "# data summary\n",
    "print(\"Summary:\\n\", glass.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning - Training a Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary package and methods, if you havne't\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# build a decision tree model\n",
    "# set the classifier\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', \n",
    "                                    max_depth=4, \n",
    "                                    random_state=1)\n",
    "\n",
    "# fit the classifier from training set\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for a new sample with features as\n",
    "\n",
    "RI | Na | Mg | Al | Si | K | Ca | Ba | Fe\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- \n",
    "1.6010| 12.51 | 1.67 | 2.15 | 72.19 | 0.79 | 9.3 | 0.28 | 0.54 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the label or class for sample with given features\n",
    "tree_model.predict([[1.6010, 12.51, 1.67, 2.15, 72.19, 0.79, 9.3, 0.28, 0.54]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for all the samples in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 2, 3, 1, 1, 1, 2, 1, 2, 2, 2, 3, 1,\n",
       "       2, 7, 3, 1, 7, 2, 2, 2, 2, 5, 7, 7, 1, 7, 2, 5, 7, 1, 5, 3, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the label for all samples in test set\n",
    "tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.57      0.57        14\n",
      "           2       0.53      0.53      0.53        15\n",
      "           3       0.20      0.33      0.25         3\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.56        43\n",
      "   macro avg       0.47      0.49      0.48        43\n",
      "weighted avg       0.55      0.56      0.55        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for DT\n",
    "# define y_pred\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# print\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Present the Decision Tree\n",
    "Please disply the decision tree structure on the screen and save it to either a pdf, jpeg, or png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# plot the tree\n",
    "tree.plot_tree(tree_model)\n",
    "# save the plot into a pdf file\n",
    "plt.savefig('images/tree_model_iris.pdf')\n",
    "# show the plot on the screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to visualize decision boundaries\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [1 2 3 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# double check the labels in samples\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning - Training a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=inf, decision_function_shape='ovo', kernel='linear', max_iter=5000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary package and methods, if you havne't\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# build a SVM Classifier model\n",
    "# set the classifier\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"), max_iter= 5000, decision_function_shape='ovo')\n",
    "\n",
    "# fit the classifier from training set\n",
    "svm_clf.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for a new sample with features as\n",
    "\n",
    "RI | Na | Mg | Al | Si | K | Ca | Ba | Fe\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- \n",
    "1.6010| 12.51 | 1.67 | 2.15 | 72.19 | 0.79 | 9.3 | 0.28 | 0.54 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "# get prediction for class with given samples\n",
    "X_new = np.array([[1.6010, 12.51, 1.67, 2.15, 72.19, 0.79, 9.3, 0.28, 0.54]])\n",
    "X_new_std = sc.transform(X_new)\n",
    "y_hat = svm_clf.predict(X_new_std)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the label or class for all the samples in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 6 1 1 1 3 1 3 3 1 1 1 3 2 3 6 1 3 2 1 7 3 1 7 2 1 2 6 1 3 7 1 7 1\n",
      " 5 7 1 7 1 1]\n"
     ]
    }
   ],
   "source": [
    "# get prediction for all the samples in the test set\n",
    "y_hats = svm_clf.predict(X_test_std)\n",
    "print(y_hats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "   class 0: buildingwindowsfloatprocessed       0.44      0.57      0.50        14\n",
      "class 1: buildingwindowsnonfloatprocessed       0.29      0.13      0.18        15\n",
      "    class 2: vehiclewindowsfloatprocessed       0.12      0.33      0.18         3\n",
      "                      class 4: containers       1.00      0.33      0.50         3\n",
      "                       class 5: tableware       0.67      1.00      0.80         2\n",
      "                       class 6: headlamps       1.00      1.00      1.00         6\n",
      "\n",
      "                                 accuracy                           0.47        43\n",
      "                                macro avg       0.59      0.56      0.53        43\n",
      "                             weighted avg       0.49      0.47      0.45        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# genereate and print the classification report\n",
    "target_names = ['class 0: buildingwindowsfloatprocessed', 'class 1: buildingwindowsnonfloatprocessed', 'class 2: vehiclewindowsfloatprocessed', 'class 4: containers', 'class 5: tableware', 'class 6: headlamps']\n",
    "\n",
    "# genereate and print the classification report\n",
    "print(classification_report(y_test, y_hats, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Describe traing samples\n",
    "- How many observations are there in the dataset? \n",
    "- How many features does each observation have? \n",
    "- What/Which columns did you include in your features? Why and Why not?\n",
    "- What/Which column did you use for the label or target value?\n",
    "- What do those values of labels mean? (You may want to check the [data source](#datasource))\n",
    "- How many samples are there in your training set? How many in the test set?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There are 214 samples in the dataset. Each observation has 10 features. We included all features other than Type. This is because Type is what we are trying to identify for the observations. The Type column was used as the label or target value, as this is what we are attempting to find. RI is the observations refractive index. Na through Fe refers to the elements weight percent in corresponding oxide for each observation (Kaggle). There are 171 samples in the training set and 43 samples in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Explore insights from the model - KNN\n",
    "- How many neighbhors did you consider in the model you built?\n",
    "- Why did you select the number? Have you changed the numbers? \n",
    "- Which distance function did you use in the model you built?\n",
    "- Why did you select that distance function? Have you tried other distance function?\n",
    "- Did any changes in the parameters or arguments (when you set the classifer) make your preidction or classificaton report different?\n",
    "- How did you or can you fine tune the KNN model?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We considered 5 neighbors in the model we built [8]. This number was used in the example KNN completed in lab. If we increased K, the learning model would take more time to run, but have less variance and smoother deicison boundaries. We used the minkowski distance function in the model we built. The minkowski distance metric is a generalized version of the euclidean and manhattan metrics which makes it a good starting point. It is also the distance metric used in the example KNN. Setting the k to 10 changes the prediction from array[5] to array[1]; however, it also lowers the accuracy of the classification report. The KNN model can be made more efficient by standardizing features. You can also modify the amount of neighbors and distance function. Models should be compared to determine if it is a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Explore insights from the model - Decision Tree\n",
    "- What is the maximum depth in the model you built? \n",
    "- Why did you selecet that number of depth?\n",
    "- Did any changes in the parameters or arguments (when you set the classifer) make your preidction or classificaton report different?\n",
    "- How did you or can you fine tune the Decision Tree model?\n",
    "- Based on your tree structure (the plot), which feature may be the most importnat feature to make the prediction?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The max depth in our model is 4[13]. Starting with a lower depth prevents overfitting data and prevents overuse of computer resources. If we wanted to change parameters, we could make the depth a larger number. This would allow the decision tree to split into more nodes, but can result in overfitting. The model can be tuned by increasing or decreasing the depth value. Doing this will prevent over- or underfitting of the dat. The random state value can also be adjusted if minima are altering your predicitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Explore insights from the model - SVM\n",
    "- Which kernel did you use in the model you built?\n",
    "- Why did you select the kernel? Have you tried other kernel?\n",
    "- Did any changes in the parameters or arguments (when you set the classifer) make your preidction or classificaton report different?\n",
    "- How did you or can you fine tune the SVM model?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We used the linear kernel. The linear kernel is a good starting point in SVM mode as it is the most simple. To make your model more sophisticated, or if your model cannot be separated into two dimensions, you can use other kernels like the RBF, non-linear, or polynomial. Changing our kernel type to 'rbf' dramatically increases the accuracy of our model. An SVM model can be fine-tuned by changing the kernel type to find what best suits your dataset. Additionally, the max iterations on the learning model can be increased, but this will also require more computer resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Compare learning algorithm\n",
    "For each learning algorithm:\n",
    " - What are the strengths or drawbacks?\n",
    " - Based on those pros and cons, which learning algorithm(s) may be proper to use? \n",
    " - How do those pros and cons affect your analyze in this assignment?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The pros of KNN are that it is simple, has a wide array of applications, and converges in large data sets. The pros of the decision tree are easy to understand, low running time, and there is no further data processing required such as normalization. SVM is effective in data with high dimensionality and when the # of features is higher than # of training data. Based on the pros and cons, an SVM model with an rbf kernel would best serve us. Because SVM is effective for data with high dimensions, it applies well to our set that has nine features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Eavluate the models\n",
    "From your classification report:\n",
    "- Which model perform the best for this dataset? What might be the reasons to cause that?\n",
    "- Which model perform the worst for this dataset? What might be the reasons to cause that?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The model that performs the best is a SVM model using the rbf kernel. This is because it accounts for the high data dimensionality. The model that peforms the worst is the decision tree. That is due to the many data features in the dataset. A very large tree would be required to raise the accuracy of the model, which would have a long run time and require more computer resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Reflect on your expereience\n",
    "When you learn and implement those classification models:\n",
    "- What is/are the most interesting part(s) for you?\n",
    "- What is/are the most challenging part(s) for you?\n",
    "- What is/are the not so fun part(s) for you?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The most interesting part to me is how we can use computer models to predict observations that may have not happened yet. It is exciting to see how data science can be analyzed to make these predicitions. The most challenging part for me is understanding the outputs, i.e. if something is 'wrong' or 'right'. The not so fun parts are trying to get cells to run when there are errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Imagine possible applications or future work \n",
    "Now, you have learned several fundemental classification learning algrithms:\n",
    "- What problems or applications (in daily life, at work, in school, or...) do you want to solve/develop using those machine learning classificaton?\n",
    "- To be able to solve the above problems or to build the applications, what kind of data or information you may need?\n",
    "\n",
    "Please answer those questions in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Developing a machine learning model to predict what genre of music a musician would play based on their geographic location. Predict what religion a person is based off geographic and biological characteristics. For the music model, you would need to know the genre of music and geographic location. The data is low dimension so it could be done with a KNN model or SVM model with a linear kernel. For the religion model, you would need to know the geographic location, race, eye color, and hair color. This is higher dimension data that could be processed with an SVM model using the rbf kernel or a decision tree with high depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
